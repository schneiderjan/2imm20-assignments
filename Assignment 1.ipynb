{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<style>html, body{overflow-y: visible !important} .CodeMirror{min-width:105% !important;} .rise-enabled .CodeMirror, .rise-enabled .output_subarea{font-size:140%; line-height:1.2; overflow: visible;} .output_subarea pre{width:110%}</style>''') # For slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Foundations of Data Mining: Assignment 1\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please fill in your names here\n",
    "NAME_STUDENT_1 = \"Jan-Niklas Schneider 1260421\"\n",
    "NAME_STUDENT_2 = \"Georgiana Manolache 0876359\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MoneyBall (5 points, 1+2+1+1)\n",
    "In the early 2000s, 2 baseball scouts completely changed the game of baseball by analysing the available data about baseball players and hiring the best ones.\n",
    "The [MoneyBall dataset](https://www.openml.org/d/41021) contains this data (click the link for more details). The goal is to accurately predict the number of 'runs' each player can score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moneyball = oml.datasets.get_dataset(41021) # Download MoneyBall data\n",
    "# Get the predictors X and the target y\n",
    "X, y, attribute_names = moneyball.get_data(target=moneyball.default_target_attribute, return_attribute_names=True)\n",
    "# Describe the data with pandas, just to get an overview\n",
    "ballframe = pd.DataFrame(X, columns=attribute_names)\n",
    "ballframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1 . Visually explore the data. Plot the distribution of each feature (e.g. histograms), as well as the target. Visualize the dependency of the target on each feature (use a 2d scatter plot). Is there anything that stands out? Is there something that you think might require special treatment?\n",
    "- Feel free to create additional plots that help you understand the data\n",
    "- Only visualize the data, you don't need to change it (yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just have a look at some details of the data frame before actually visualize sutff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(attribute_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ballframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ballframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 15):\n",
    "    print(ballframe.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('targets')\n",
    "print(y)\n",
    "print(\"nr of targets {0}\".format(len(np.unique(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ballframe['Team'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some teams are more often in data; probably due to having more games in play offs.\n",
    "All data is encoded as floats.\n",
    "What I want to do now is to see whats different between those teams with 47 appearances to the other ones.\n",
    "[An Examination of the Moneyball Theory: A Baseball Statistical Analysis](http://thesportjournal.org/article/an-examination-of-the-moneyball-theory-a-baseball-statistical-analysis/)\n",
    "this link might be interesting. not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "p = scatter_matrix(ballframe, alpha=0.2, figsize=(20, 16), diagonal='kde')\n",
    "plt.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ballframe['RS'] = pd.Series(y, index=ballframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "fig.suptitle(\"Offensive stats and its impact on Runs Scored and Wins\")\n",
    "ax1 = fig.add_subplot(3,2,1)\n",
    "ax2 = fig.add_subplot(3,2,2)\n",
    "ax3 = fig.add_subplot(3,2,3)\n",
    "ax4 = fig.add_subplot(3,2,4)\n",
    "ax5 = fig.add_subplot(3,2,5)\n",
    "ax6 = fig.add_subplot(3,2,6)\n",
    "sns.regplot(x=\"OBP\", y=\"RS\", data=ballframe, scatter=True, marker=\"+\", ax=ax1)\n",
    "sns.regplot(x=\"SLG\", y=\"RS\", data=ballframe, scatter=True, marker=\"+\", ax=ax2)\n",
    "sns.regplot(x=\"OBP\", y=\"W\", data=ballframe, scatter=True, marker=\"+\", ax=ax3)\n",
    "sns.regplot(x=\"SLG\", y=\"W\", data=ballframe, scatter=True, marker=\"+\", ax=ax4)\n",
    "sns.regplot(x=\"BA\", y=\"RS\", data=ballframe, scatter=True, marker=\"+\", ax=ax5)\n",
    "sns.regplot(x=\"BA\", y=\"W\", data=ballframe, scatter=True, marker=\"+\", ax=ax6)\n",
    "ax1.set_xlabel(\"On-Base %\")\n",
    "ax1.set_ylabel(\"Runs Scored\")\n",
    "ax2.set_xlabel(\"Slugging %\")\n",
    "ax2.set_ylabel(\"Runs Scored\")\n",
    "ax3.set_xlabel(\"On-Base %\")\n",
    "ax3.set_ylabel(\"Wins\")\n",
    "ax4.set_xlabel(\"Slugging %\")\n",
    "ax4.set_ylabel(\"Wins\")\n",
    "ax5.set_xlabel(\"Batting Average\")\n",
    "ax5.set_ylabel(\"Runs Scored\")\n",
    "ax6.set_xlabel(\"Batting Average\")\n",
    "ax6.set_ylabel(\"Wins\")\n",
    "ax4.set_ylim([40,120])\n",
    "ax6.set_ylim([40,120])\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2 . Compare all linear regression algorithms that we covered in class (Linear Regression, Ridge, Lasso and ElasticNet), as well as kNN. Evaluate using cross-validation and the $R^2$ score, with the default parameters. Does scaling the data with StandardScaler help? Provide a concise but meaningful interpretation of the results.\n",
    "- Preprocess the data as needed (e.g. are there nominal features that are not ordinal?). If you don't know how to proceed, remove the feature and continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3 . Do a default, shuffled train-test split and optimize the linear models for the degree of regularization ($alpha$) and choice of penalty (L1/L2). For Ridge and  Lasso, plot a curve showing the effect of the training and test set performance ($R^2$) while increasing the degree of regularization for different penalties. For ElasticNet, plot a heatmap $alpha \\times l1\\_ratio \\rightarrow R^2$ using test set performance.\n",
    "Report the optimal performance. Again, provide a concise but meaningful interpretation. What does the regularization do? Can you get better results?\n",
    "- Think about how you get the L1/L2 loss. This is not a hyperparameter in regression.\n",
    "- We've seen how to generate such heatmaps in Lecture 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4 . Visualize the coefficients of the optimized models. Do they agree on which features are\n",
    "important? Compare the results with the feature importances returned by a RandomForest. Do it agree with the linear models? What would look for when scouting for a baseball player?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nepalese character recognition (5 points, 1+2+2)\n",
    "The [Devnagari-Script dataset](https://www.openml.org/d/40923) contains 92,000 images (32x32 pixels) of 46 characters from Devanagari script. Your goal is to learn to recognize the right letter given the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devnagari = oml.datasets.get_dataset(40923) # Download Devnagari data\n",
    "# Get the predictors X and the labels y\n",
    "X, y = devnagari.get_data(target=devnagari.default_target_attribute); \n",
    "classes = devnagari.retrieve_class_labels(target_name='character') # This one takes a while, skip if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "# Take some random examples, reshape to a 32x32 image and plot\n",
    "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    n = randint(0,90000)\n",
    "    axes[i].imshow(X[n].reshape(32, 32), cmap=plt.cm.gray_r)\n",
    "    axes[i].set_xlabel(\"Class: %s\" % (classes[y[n]]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=1250, train_size=5000, stratify=y) #25% of 5000\n",
    "#stratified 10% subsample of the data\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Evaluate k-Nearest Neighbors, Logistic Regression and RandomForests with their default settings.\n",
    "    - Take a stratified 10% subsample of the data.\n",
    "    - Use the default train-test split and predictive accuracy. Is predictive accuracy a good scoring measure for this problem?\n",
    "    - Try to build the same models on increasingly large samples of the dataset (e.g. 10%, 20%,...). Plot the training time and the predictive performance for each. Stop when the training time becomes prohibitively large (this will be different for different models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "\n",
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg100.score(X_test, y_test)))\n",
    "\n",
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2 . Optimize the value for the number of neighbors $k$ (keep $k$ < 50) and the number of trees (keep $n\\_estimators$ < 100) on the stratified 10% subsample.\n",
    "- Use 10-fold crossvalidation and plot $k$ and $n\\_estimators$ against the predictive accuracy. Which value of $k$, $n\\_estimators$ should you pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3 . For the RandomForest, optimize both $n\\_estimators$ and $max\\_features$ at the same time on the entire dataset.\n",
    "- Use a nested cross-validation and a random search over the possible values, and measure the accuracy. Explore how fine-grained this grid/random search can be, given your computational resources. What is the optimal performance you find?\n",
    "- Hint: choose a nested cross-validation that is feasible. Don't use too many folds in the outer loop.\n",
    "- Repeat the grid search and visualize the results as a plot (heatmap) $n\\_estimators \\times max\\_features \\rightarrow ACC$ with ACC visualized as the color of the data point. Try to make the grid as fine as possible. Interpret the results. Can you explain your observations? What did you learn about tuning RandomForests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Understanding Ensembles (5 points (3+2))\n",
    "Do a deeper analysis of how RandomForests and Gradient Boosting reduce their prediction error. We'll use the MAGIC telescope dataset (http://www.openml.org/d/1120). When high-energy particles hit the atmosphere, they produce chain reactions of other particles called 'showers', and you need to detect whether these are caused by gamma rays or cosmic rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "magic_data = oml.datasets.get_dataset(1120) # Download MAGIC Telescope data\n",
    "X, y = magic_data.get_data(target=magic_data.default_target_attribute);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick visualization\n",
    "X, y, attribute_names = magic_data.get_data(target=magic_data.default_target_attribute, return_attribute_names=True)\n",
    "magic = pd.DataFrame(X, columns=attribute_names)\n",
    "magic.plot(figsize=(20,10))\n",
    "# Also plot the target: 1 = gamma, 0 = background\n",
    "pd.DataFrame(y).plot(figsize=(20,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1 . Do a bias-variance analysis of both algorithms. For each, vary the number of trees on a log scale from 1 to 1024, and plot the bias error (squared), variance, and total error (in one plot per algorithm). Interpret the results. Which error is highest for small ensembles, and which reduced most by each algorithm as you use a larger ensemble? When are both algorithms under- or overfitting? Provide a detailed explanation of why random forests and gradient boosting behave this way.\n",
    "- See lecture 3 for an example on how to do the bias-variance decomposition\n",
    "- To save time, you can use a 10% stratified subsample in your initial experiments, but show the plots for the full dataset in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2 . A _validation curve_ can help you understand when a model starts under- or overfitting. It plots both training and test set error as you change certain characteristics of your model, e.g. one or more hyperparameters. Build validation curves for gradient boosting, evaluated using AUROC, by varying the number of iterations between 1 and 500. In addition, use at least two values for the learning rate (e.g. 0.1 and 1), and tree depth (e.g. 1 and 4). This will yield at least 4 curves. Interpret the results and provide a clear explanation for the results. When is the model over- or underfitting? Discuss the effect of the different combinations learning rate and tree depth and provide a clear explanation.\n",
    "- While scikit-learn has a `validation_curve` function, we'll use a modified version (below) that provides a lot more detail and can be used to study more than one hyperparameter. You can use a default train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plots validation curves for every classifier in clfs. \n",
    "# Also indicates the optimal result by a vertical line\n",
    "# Uses 1-AUROC, so lower is better\n",
    "def validation_curve(clfs, X_test, y_test, X_train, y_train):\n",
    "    for n,clf in enumerate(clfs):\n",
    "        test_score = np.empty(len(clf.estimators_))\n",
    "        train_score = np.empty(len(clf.estimators_))\n",
    "\n",
    "        for i, pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "            test_score[i] = 1-roc_auc_score(y_test, pred)\n",
    "\n",
    "        for i, pred in enumerate(clf.staged_decision_function(X_train)):\n",
    "            train_score[i] = 1-roc_auc_score(y_train, pred)\n",
    "\n",
    "        best_iter = np.argmin(test_score)\n",
    "        learn = clf.get_params()['learning_rate']\n",
    "        depth = clf.get_params()['max_depth']\n",
    "        test_line = plt.plot(test_score,\n",
    "                             label='learn=%.1f depth=%i (%.2f)'%(learn,depth,\n",
    "                                                                 test_score[best_iter]))\n",
    "\n",
    "        colour = test_line[-1].get_color()\n",
    "        plt.plot(train_score, '--', color=colour)\n",
    "        \n",
    "        plt.xlabel(\"Number of boosting iterations\")\n",
    "        plt.ylabel(\"1 - area under ROC\")\n",
    "        plt.axvline(x=best_iter, color=colour)\n",
    "        \n",
    "    plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
